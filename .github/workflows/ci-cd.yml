name: Infrastructure CI/CD

permissions:
  contents: read
  secrets: read

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  verify-secrets:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Install GitHub CLI
      run: |
        sudo apt-get update
        sudo apt-get install -y gh
        gh auth login --with-token <<< "${{ secrets.GITHUB_TOKEN }}"
    
    - name: List and verify GitHub secrets
      run: |
        echo "Listing GitHub secrets..."
        gh secret list --json name --jq '.[].name' || (echo "Error: Failed to list GitHub secrets"; exit 1)
        
        echo "Verifying required secrets..."
        REQUIRED_SECRETS=(
          "CF_TUNNEL_TOKEN"
          "AWS_ACCESS_KEY_ID"
          "AWS_SECRET_ACCESS_KEY"
          "AWS_DEFAULT_REGION"
          "SSH_PRIVATE_KEY"
          "SSH_KNOWN_HOSTS"
          "SSH_USER"
          "SSH_HOST"
        )
        
        for secret in "${REQUIRED_SECRETS[@]}"; do
          if ! gh secret list --json name --jq '.[].name' | grep -q "^${secret}$"; then
            echo "Error: Required secret '${secret}' is missing in GitHub secrets"
            exit 1
          fi
        done
        
        echo "All required secrets are present in GitHub secrets"
        
  validate-configs:
    needs: verify-secrets
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Validate Docker Compose files
      run: |
        echo "Validating docker-compose.yml..."
        docker-compose -f docker-compose.yml config || (echo "Error: docker-compose.yml validation failed"; exit 1)
        
        echo "Validating docker-compose.fail2ban.yml..."
        docker-compose -f docker-compose.fail2ban.yml config || (echo "Error: docker-compose.fail2ban.yml validation failed"; exit 1)
        
    - name: Validate Traefik config
      run: |
        echo "Validating Traefik configuration..."
        docker run -v ${{ github.workspace }}/traefik:/etc/traefik:ro traefik:v2.10 traefik validate --check || (echo "Error: Traefik configuration validation failed"; exit 1)

  test-containers:
    runs-on: ubuntu-latest
    needs: validate-configs
    services:
      docker:
        image: docker:dind
        options: --privileged
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
      
    - name: Create test environment
      run: |
        echo "Creating test environment..."
        mkdir -p nginx/certs cloudflared
        touch .env
        echo "JUPYTER_TOKEN=test-token" >> .env
        echo "TUNNEL_TOKEN=${{ secrets.CF_TUNNEL_TOKEN }}" >> .env
        echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> .env
        echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> .env
        echo "AWS_DEFAULT_REGION=${{ secrets.AWS_DEFAULT_REGION }}" >> .env
        
    - name: Build and test containers
      run: |
        echo "Starting containers..."
        docker-compose -f docker-compose.yml up -d || (echo "Error: Failed to start containers"; exit 1)
        
        echo "Checking container status..."
        docker-compose ps || (echo "Error: Container status check failed"; exit 1)
        
        echo "Waiting for services to initialize..."
        sleep 30
        
    - name: Test service health
      run: |
        echo "Testing Jupyter health..."
        curl -f http://localhost:8888/api/status || (echo "Error: Jupyter health check failed"; exit 1)
        
        echo "Testing Dagster health..."
        curl -f http://localhost:3000/health || (echo "Error: Dagster health check failed"; exit 1)
        
        echo "Testing SearxNG health..."
        curl -f http://localhost:8889/status || (echo "Error: SearxNG health check failed"; exit 1)
        
    - name: Run security scans
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'table'
        exit-code: '1'
        severity: 'CRITICAL,HIGH'
      continue-on-error: true  # Allow the workflow to continue even if vulnerabilities are found
        
    - name: Test fail2ban integration
      run: |
        echo "Starting fail2ban..."
        docker-compose -f docker-compose.fail2ban.yml up -d || (echo "Error: Failed to start fail2ban"; exit 1)
        
        echo "Waiting for fail2ban to initialize..."
        sleep 10
        
        echo "Checking fail2ban status..."
        docker-compose exec -T fail2ban fail2ban-client status || (echo "Error: fail2ban status check failed"; exit 1)
        
        echo "Viewing fail2ban logs..."
        docker-compose logs fail2ban || (echo "Error: Failed to view fail2ban logs"; exit 1)
        
    - name: Cleanup
      if: always()
      run: |
        echo "Cleaning up containers..."
        docker-compose down -v || (echo "Error: Failed to clean up containers"; exit 1)
        
        echo "Pruning Docker system..."
        docker system prune -f || (echo "Error: Failed to prune Docker system"; exit 1)

  deploy:
    if: github.ref == 'refs/heads/main'
    needs: test-containers
    runs-on: ubuntu-latest
    environment: production
    steps:
    - uses: actions/checkout@v3
    
    - name: Install SSH key
      uses: shimataro/ssh-key-action@v2
      with:
        key: ${{ secrets.SSH_PRIVATE_KEY }}
        known_hosts: ${{ secrets.SSH_KNOWN_HOSTS }}
        if_key_exists: replace
        
    - name: Deploy to production
      env:
        SSH_USER: ${{ secrets.SSH_USER }}
        SSH_HOST: ${{ secrets.SSH_HOST }}
        DEPLOY_PATH: /home/${{ secrets.SSH_USER }}/infrastructure
      run: |
        echo "Creating deployment script..."
        echo "#!/bin/bash
        set -e
        cd \$DEPLOY_PATH

        # Ensure .env file exists and is not in git
        touch .env
        echo '.env' >> .gitignore

        # Pull latest code without overwriting .env
        git stash -u
        git pull origin main
        git stash pop || true

        # Update containers
        docker-compose pull
        docker-compose -f docker-compose.yml -f docker-compose.fail2ban.yml down
        docker-compose -f docker-compose.yml -f docker-compose.fail2ban.yml up -d

        # Cleanup
        docker system prune -f" > deploy.sh
        chmod +x deploy.sh
        
        echo "Copying deployment script to production server..."
        scp -o StrictHostKeyChecking=no deploy.sh $SSH_USER@$SSH_HOST:$DEPLOY_PATH/ || (echo "Error: Failed to copy deployment script"; exit 1)
        
        echo "Executing deployment script..."
        ssh -o StrictHostKeyChecking=no $SSH_USER@$SSH_HOST "cd $DEPLOY_PATH && ./deploy.sh" || (echo "Error: Deployment script failed"; exit 1)
        
    - name: Verify deployment
      env:
        SSH_USER: ${{ secrets.SSH_USER }}
        SSH_HOST: ${{ secrets.SSH_HOST }}
        DEPLOY_PATH: /home/${{ secrets.SSH_USER }}/infrastructure
      run: |
        echo "Verifying deployment..."
        ssh -o StrictHostKeyChecking=no $SSH_USER@$SSH_HOST "cd $DEPLOY_PATH && \
          docker-compose ps && \
          docker-compose logs --tail=50 && \
          echo 'Checking service health...' && \
          for service in \$(docker-compose ps --services); do
            echo \"Checking \$service...\"
            docker-compose ps \$service | grep -q \"healthy\" || (echo \"Error: Service \$service is not healthy\"; exit 1)
          done" || (echo "Error: Deployment verification failed"; exit 1)

    - name: Notify on failure
      if: failure()
      run: |
        echo "Deployment failed! Check the logs for details."
        exit 1
